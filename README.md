# ğŸ­ Facial Recognition with Voice Assistant

Real-time facial recognition application using **YOLOv8** for detection, **Moondream** for scene analysis, and **voice commands** for hands-free operation.

![License](https://img.shields.io/badge/license-MIT-blue.svg)
![Node](https://img.shields.io/badge/node-18%2B-green.svg)
![Python](https://img.shields.io/badge/python-3.9%2B-blue.svg)

---

## âœ¨ Features

- ğŸ” **Real-time Face Detection** â€” YOLOv8 running in-browser (ONNX) or via local Python server
- ğŸ§  **AI Scene Analysis** â€” Moondream model describes scenes, detects emotions, and answers questions
- ğŸ¤ **Voice Commands** â€” Hands-free operation with natural language commands
- ğŸ”’ **Fully Offline** â€” All processing happens locally, no data leaves your machine
- âš¡ **Dual Processing Modes** â€” Browser-based ONNX or GPU-accelerated Python backend

---

## ğŸ› ï¸ Tech Stack

| Layer | Technology |
|-------|------------|
| **Frontend** | React, TypeScript, Vite |
| **Vision (Browser)** | ONNX Runtime Web, YOLOv8n-face |
| **Vision (Server)** | Python, Ultralytics YOLOv8, FastAPI |
| **AI Analysis** | Ollama + Moondream |
| **Voice** | Web Speech API |

---

## ğŸ“‹ Prerequisites

Before you begin, ensure you have the following installed:

- **Node.js** 18+ â€” [Download](https://nodejs.org/)
- **Python** 3.9+ â€” [Download](https://python.org/)
- **Ollama** â€” [Download](https://ollama.ai/)

---

## ğŸš€ Installation

### 1. Clone the Repository

```bash
git clone https://github.com/[username]/Facial-Recognition.git
cd Facial-Recognition
```

### 2. Install Frontend Dependencies

```bash
npm install
```

### 3. Download Models

#### Browser ONNX Model
Download `yolov8n-face.onnx` and place it in:
```
public/models/yolov8n-face.onnx
```

> ğŸ“¥ Download from: [YOLOv8-face ONNX](https://github.com/akanametov/yolov8-face) or export using Ultralytics

#### Python YOLOv8 Model
The `yolov8n.pt` model will auto-download when you first run the vision server via Ultralytics.

### 4. Set Up Python Vision Server

```bash
cd vision-server

# Create virtual environment
python -m venv venv

# Activate virtual environment (Windows)
venv\Scripts\activate

# Activate virtual environment (macOS/Linux)
# source venv/bin/activate

# Install dependencies
pip install -r requirements.txt
```

### 5. Install Ollama and Moondream

```bash
# Pull the Moondream vision model
ollama pull moondream
```

---

## â–¶ï¸ Running the Application

You'll need **3 terminals** running simultaneously:

### Terminal 1 â€” Ollama Server

```bash
ollama serve
```

> Runs on `http://localhost:11434`

### Terminal 2 â€” Python Vision Server

```bash
cd vision-server
venv\Scripts\activate
python vision_server.py
```

> Runs on `http://localhost:8000`

### Terminal 3 â€” React Frontend

```bash
npm run dev
```

> Open **http://localhost:3001** in your browser

---

## ğŸ¤ Voice Commands

| Command | Action |
|---------|--------|
| `"Begin detections"` | Starts YOLOv8 face scanning |
| `"Stop detections"` | Stops the scanning process |
| `"What do you see?"` | Describes the current scene |
| `"How many people?"` | Counts detected faces |
| `"Is anyone smiling?"` | Analyzes emotions in frame |
| `"Describe the person"` | Detailed description of detected face |

---

## ğŸ“¡ API Endpoints (Vision Server)

### Health Check
```http
GET /health
```
Returns server status and available models.

### Face Detection
```http
POST /detect/faces
Content-Type: multipart/form-data

file: <image>
```
Returns bounding boxes and confidence scores for detected faces.

### Object Detection
```http
POST /detect/objects
Content-Type: multipart/form-data

file: <image>
```
Returns detected objects with labels and bounding boxes.

### Moondream Analysis
```http
POST /analyze
Content-Type: multipart/form-data

file: <image>
prompt: "What do you see in this image?"
```
Returns AI-generated scene description.

### Combined Vision Query
```http
POST /vision/query
Content-Type: multipart/form-data

file: <image>
query: "How many people are there and what are they doing?"
```
Combines YOLOv8 detection with Moondream analysis.

---

## ğŸ—ï¸ Project Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                         React Frontend                          â”‚
â”‚                   (TypeScript + Vite + Voice)                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                 â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚  visionService  â”‚    â”‚ localVisionSvc  â”‚    â”‚ ollamaServiceâ”‚ â”‚
â”‚  â”‚  (Browser ONNX) â”‚    â”‚ (Python Server) â”‚    â”‚ (Moondream) â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚           â”‚                      â”‚                     â”‚        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”˜
            â”‚                      â”‚                     â”‚
            â–¼                      â–¼                     â–¼
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚  ONNX Runtime â”‚      â”‚ Python Vision â”‚     â”‚    Ollama     â”‚
    â”‚     (Web)     â”‚      â”‚    Server     â”‚     â”‚    Server     â”‚
    â”‚               â”‚      â”‚   (FastAPI)   â”‚     â”‚  (Moondream)  â”‚
    â”‚ yolov8n-face  â”‚      â”‚   YOLOv8n.pt  â”‚     â”‚               â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         Browser              :8000                  :11434
```

### Data Flow

1. **Camera Feed** â†’ Captured via browser MediaDevices API
2. **Frame Processing** â†’ Sent to either browser ONNX or Python server
3. **Face Detection** â†’ YOLOv8 returns bounding boxes
4. **Scene Analysis** â†’ Cropped faces/frames sent to Moondream
5. **Voice Output** â†’ Results spoken via Web Speech API

---

## ğŸ“ Project Structure

```
Facial-Recognition/
â”œâ”€â”€ src/                          # React TypeScript frontend
â”‚   â”œâ”€â”€ services/
â”‚   â”‚   â”œâ”€â”€ visionService.ts      # Browser ONNX YOLOv8
â”‚   â”‚   â”œâ”€â”€ localVisionService.ts # Calls Python server
â”‚   â”‚   â”œâ”€â”€ ollamaService.ts      # Ollama/Moondream integration
â”‚   â”‚   â””â”€â”€ moondreamService.ts   # Moondream analysis
â”‚   â”œâ”€â”€ components/               # React components
â”‚   â””â”€â”€ App.tsx
â”œâ”€â”€ public/
â”‚   â””â”€â”€ models/
â”‚       â””â”€â”€ yolov8n-face.onnx     # Browser ONNX model
â”œâ”€â”€ vision-server/                # Python backend
â”‚   â”œâ”€â”€ venv/                     # Python virtual environment
â”‚   â”œâ”€â”€ vision_server.py          # FastAPI server
â”‚   â””â”€â”€ requirements.txt          # Python dependencies
â”œâ”€â”€ package.json
â”œâ”€â”€ tsconfig.json
â”œâ”€â”€ vite.config.ts
â””â”€â”€ README.md
```

---

## ğŸ”§ Configuration

### Frontend Environment Variables

Create a `.env.local` file in the project root:

```env
VITE_VISION_SERVER_URL=http://localhost:8000
VITE_OLLAMA_URL=http://localhost:11434
```

### Vision Server Configuration

Edit `vision_server.py` to adjust:
- Model paths
- Confidence thresholds
- CORS settings

---

## ğŸ› Troubleshooting

### "Cannot connect to Ollama"
```bash
# Ensure Ollama is running
ollama serve

# Verify Moondream is installed
ollama list
```

### "ONNX model not loading"
- Verify `public/models/yolov8n-face.onnx` exists
- Check browser console for CORS errors

### "Python server won't start"
```bash
# Ensure virtual environment is activated
venv\Scripts\activate  # Windows
source venv/bin/activate  # macOS/Linux

# Reinstall dependencies
pip install -r requirements.txt
```

### "Voice commands not working"
- Use Chrome or Edge (best Web Speech API support)
- Allow microphone permissions
- Speak clearly and wait for the listening indicator

---

## ğŸ“„ License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

---

## ğŸ¤ Contributing

Contributions are welcome! Please feel free to submit a Pull Request.

1. Fork the repository
2. Create your feature branch (`git checkout -b feature/AmazingFeature`)
3. Commit your changes (`git commit -m 'Add some AmazingFeature'`)
4. Push to the branch (`git push origin feature/AmazingFeature`)
5. Open a Pull Request

---

## ğŸ“¬ Contact

For questions or support, please open an issue on GitHub.

---

<p align="center">
  Made with â¤ï¸ using YOLOv8, Moondream, and React
</p>
